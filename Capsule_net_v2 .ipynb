{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dimension = 90\n",
    "frames = 100\n",
    "\n",
    "x = tf.placeholder(shape = [None,feature_dimension,frames], dtype = tf.float32)\n",
    "y = tf.placeholder(shape = [None,2], dtype = tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the input\n",
    "input_x = tf.reshape(x,[-1,feature_dimension,frames,1])\n",
    "conv1 = tf.layers.conv2d(input_x,\n",
    "                        filters = 32,\n",
    "                        kernel_size = 9,\n",
    "                        activation = tf.nn.relu,\n",
    "                        padding = 'VALID',\n",
    "                        name = 'conv1'\n",
    "                        )\n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1,\n",
    "                        filters = 32,\n",
    "                        kernel_size = 9,\n",
    "                        activation = tf.nn.relu,\n",
    "                        padding = 'VALID',\n",
    "                        name = 'conv2'\n",
    "                        )\n",
    "\n",
    "conv_out = tf.layers.conv2d(conv2,\n",
    "                        filters = 32,\n",
    "                        kernel_size = 9,\n",
    "                        activation = tf.nn.relu,\n",
    "                        padding = 'VALID',\n",
    "                        name = 'conv_out'\n",
    "                        )\n",
    "\n",
    "eplison = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_out/Relu:0' shape=(?, 66, 76, 32) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector,axis = -2, keep_dims = True):\n",
    "    squared_norm = tf.reduce_sum(tf.square(vector), axis = axis, keep_dims = keep_dims)\n",
    "    squash_factor = squared_norm / (1. + squared_norm)\n",
    "    safe_norm = tf.sqrt(squared_norm + eplison)\n",
    "    unit_vector = vector / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primary capsules\n",
    "\n",
    "vector_dimension = 8\n",
    "total_capsules = int(conv_out.shape[1]*conv_out.shape[2]*conv_out.shape[3] // vector_dimension )\n",
    "raw_capsules = tf.reshape(conv_out ,shape = [-1, total_capsules , vector_dimension])\n",
    "primary_capsules = squash(raw_capsules,-1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", shape=(?, 20064, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(primary_capsules)\n",
    "batch_size = tf.shape(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 20064, 512) dtype=float32_ref>\n",
      "Tensor(\"Tile:0\", shape=(?, 20064, 512), dtype=float32)\n",
      "Tensor(\"transpose:0\", shape=(8, 20064, ?), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, 512, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "selected_capsules_number = 512\n",
    "\n",
    "selected_capsules_weights = tf.Variable( tf.random_normal(shape = [1,total_capsules,selected_capsules_number],\n",
    "                                        stddev = 0.1,\n",
    "                                       dtype = tf.float32))\n",
    "print(selected_capsules_weights)\n",
    "\n",
    "selected_capsules_weights_batches = tf.tile(selected_capsules_weights, [batch_size, 1, 1])\n",
    "print(selected_capsules_weights_batches)\n",
    "print(tf.transpose(primary_capsules))\n",
    "selected_capsules = tf.matmul(primary_capsules,selected_capsules_weights_batches, transpose_a = True)\n",
    "\n",
    "selected_capsules = tf.reshape(selected_capsules , shape = [-1,selected_capsules_number, vector_dimension])\n",
    "print(selected_capsules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'digit_capsule_weights:0' shape=(1, 512, 2, 16, 8) dtype=float32_ref>\n",
      "Tensor(\"digit_capsule_weights_tiled:0\", shape=(?, 512, 2, 16, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_vector = 16\n",
    "output_labels = 2                                                     # [?,1152,2,16,8]\n",
    "\n",
    "digit_capsule_weights = tf.Variable( tf.random_normal(shape = [1, selected_capsules_number, output_labels, output_vector, vector_dimension ],\n",
    "                                                     stddev = 0.1,\n",
    "                                                     dtype = tf.float32),\n",
    "                                                       name = 'digit_capsule_weights')\n",
    "print(digit_capsule_weights)\n",
    "batch_size = tf.shape(x)[0]   #knows the shape of the tensor at the run time\n",
    "digit_capsule_weights_tiled = tf.tile(digit_capsule_weights,[batch_size, 1, 1, 1, 1], name = 'digit_capsule_weights_tiled')\n",
    "\n",
    "print(digit_capsule_weights_tiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"selected_caps_reshape_tiled:0\", shape=(?, 512, 2, 8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "                                                                #\n",
    "\n",
    "selected_caps_reshape = tf.reshape(selected_capsules, shape = [batch_size, selected_capsules_number, 1, vector_dimension, 1],\n",
    "                                  name = 'selected_caps_reshape')\n",
    "selected_caps_reshape_tiled = tf.tile(selected_caps_reshape,\n",
    "                                          [1, 1, output_labels, 1 , 1 ],\n",
    "                                         name = 'selected_caps_reshape_tiled')\n",
    "print(selected_caps_reshape_tiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"raw_predictions:0\", shape=(?, 512, 2, 16, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "all_capsules_pred_output = tf.matmul(digit_capsule_weights_tiled,selected_caps_reshape_tiled ,\n",
    "                                    name = 'raw_predictions')\n",
    "print(all_capsules_pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"weighted_predictions:0\", shape=(?, 512, 2, 16, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# dymanic routing 1\n",
    "\n",
    "raw_weights = tf.zeros([batch_size, selected_capsules_number, output_labels, 1 , 1 ],\n",
    "                          dtype = tf.float32,\n",
    "                          name = 'raw_weights')\n",
    "routing_weights = tf.nn.softmax(raw_weights,\n",
    "                               dim = 2,\n",
    "                                name = 'routing_weights')\n",
    "weighted_predictions = tf.multiply(routing_weights, all_capsules_pred_output,\n",
    "                                  name = 'weighted_predictions')\n",
    "print(weighted_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul_1:0' shape=(?, 1, 2, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum over all 512 capsules\n",
    "\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, \n",
    "                            axis = 1, keep_dims = True,\n",
    "                            name = 'weighted_sum')\n",
    "pred_vector_r1 = squash(weighted_sum)\n",
    "\n",
    "pred_vector_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_2:0\", shape=(1, 16, 2, 512, ?), dtype=float32)\n",
      "Tensor(\"Tile_1:0\", shape=(?, 512, 2, 16, 1), dtype=float32)\n",
      "Tensor(\"agreements:0\", shape=(?, 512, 2, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# agreements\n",
    "pred_vector_r1_tiled = tf.tile(pred_vector_r1,\n",
    "                              [1,selected_capsules_number, 1, 1, 1])\n",
    "\n",
    "print(tf.transpose(all_capsules_pred_output))\n",
    "print(pred_vector_r1_tiled)\n",
    "agreements = tf.matmul(all_capsules_pred_output,pred_vector_r1_tiled, \n",
    "                     transpose_a = True, name = 'agreements')\n",
    "print(agreements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul_2:0\", shape=(?, 1, 2, 16, 1), dtype=float32)\n",
      "Tensor(\"Sqrt_3:0\", shape=(?, 1, 2, 1), dtype=float32)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Tensor(\"Reshape_8:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"Reshape_9:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# round 2\n",
    "\n",
    "raw_weights = raw_weights + agreements\n",
    "routing_weights_r2 = tf.nn.softmax(raw_weights,\n",
    "                               dim = 2,\n",
    "                                name = 'routing_weights_r2')\n",
    "weighted_predictions_r2 = tf.multiply(routing_weights_r2, all_capsules_pred_output,\n",
    "                                  name = 'weighted_predictions_r2')\n",
    "weighted_sum_r2 = tf.reduce_sum(weighted_predictions_r2, \n",
    "                            axis = 1, keep_dims = True,\n",
    "                            name = 'weighted_sum_r2')\n",
    "pred_vector_r2 = squash(weighted_sum_r2)\n",
    "\n",
    "print(pred_vector_r2)\n",
    "epsilon = 1e-7\n",
    "predicted_vector = pred_vector_r2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sum_squares = tf.reduce_sum( tf.square(predicted_vector), axis = -2, keep_dims = False, name = 'sum_squares')\n",
    "safe_norm = tf.sqrt(sum_squares + epsilon)\n",
    "print(safe_norm)\n",
    "\n",
    "pred_prob = tf.reshape(safe_norm, shape =  [batch_size ,2])\n",
    "pred_labels = tf.argmax(pred_prob, axis = 1)\n",
    "print(pred_labels)\n",
    "\n",
    "\n",
    "# loss\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lamda =  - 0.5\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0.0, m_plus - safe_norm))\n",
    "present_error = tf.reshape(present_error_raw, shape = [-1, 2])\n",
    "print(present_error)\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0.0, safe_norm - m_minus))\n",
    "absent_error = tf.reshape(absent_error_raw, shape = [-1, 2])\n",
    "print(absent_error)\n",
    "\n",
    "T = y\n",
    "\n",
    "L = tf.add(T * present_error , lamda * ((1.0 - T) * absent_error), name = 'L')\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis = 1), name = 'margin_loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_step = optimizer.minimize(margin_loss, name = 'train_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eer(scores_true, scores_false):\n",
    "    \n",
    "    \"\"\" Calculate EER\n",
    "        Args:\n",
    "            scores_true: A score list of positive samples\n",
    "            scores_false: A score list of negative samples\n",
    "        Return:\n",
    "            (EER, threshold)\n",
    "        Note:\n",
    "            Here, the threshold is set, and if the score is higher than or equal to the threshold,\n",
    "            the decision is passed, and the decision is rejected as below.\n",
    "    \"\"\"\n",
    "    min1 = min(scores_true)\n",
    "    min2 = min(scores_false)\n",
    "    low = min(min1, min2)\n",
    "    max1 = max(scores_true)\n",
    "    max2 = max(scores_false)\n",
    "    high = max(max1, max2)\n",
    "    FAR = -55\n",
    "    FRR = -55\n",
    "    mid = -100\n",
    "    # Bisection find threshold\n",
    "    while True:\n",
    "        bef_FAR = FAR \n",
    "        bef_FRR = FRR\n",
    "        bef_mid = mid\n",
    "        mid = (high + low) / 2\n",
    "        FRR = sum([1 for s in scores_true if s < mid]) / len(scores_true)\n",
    "        FAR = sum([1 for s in scores_false if s >= mid]) / len(scores_false)\n",
    "        #print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "\n",
    "        if abs(FRR - FAR) < 1e-7:\n",
    "            print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "            break\n",
    "\n",
    "        if FRR < FAR:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "            \n",
    "        if bef_FAR == FAR :\n",
    "            if bef_FRR == FRR :\n",
    "                if bef_mid == mid :\n",
    "                    print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "                    break\n",
    "\n",
    "    EER  =  FRR\n",
    "    return EER, (high + low) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "def get_EER(test_path, index, sp_path ):\n",
    "    scores = []\n",
    "    development_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    #test_path = \"C:\\\\Users\\\\project1\\\\Desktop\\\\Siva\\\\HT_IFCC_hemlata\\\\CNN_input_testing_dev\"\n",
    "    indexs = (len(list(os.listdir(test_path))))//2\n",
    "    \n",
    "    for folders in range(1, indexs+1):\n",
    "        features = np.load(os.path.join(test_path, \"features_\"+str(folders)+\".npy\"))\n",
    "        labels = np.load(os.path.join(test_path, \"labels_\"+str(folders)+\".npy\"))\n",
    "        patches = labels.shape[0]\n",
    "        patch_prob = session.run(pred_prob, feed_dict = {x:features})\n",
    "        final_prob = np.zeros([2])\n",
    "        \n",
    "        for i in range(patches):\n",
    "            if(patch_prob[i][0] == 0):\n",
    "                patch_prob[i][0] = 1e-25\n",
    "            if(patch_prob[i][1] == 0):\n",
    "                patch_prob[i][1] = 1e-25\n",
    "                \n",
    "            final_prob[0] = final_prob[0] + np.log(patch_prob[i][0])\n",
    "            final_prob[1] = final_prob[1] + np.log(patch_prob[i][1])\n",
    "\n",
    "        final_prob = final_prob / patches\n",
    "        score = (final_prob[0]) - (final_prob[1])\n",
    "        audio_label = labels[0]\n",
    "\n",
    "        scores.append(score)\n",
    "        probabilities.append( np.mean(patch_prob, axis=0) )\n",
    "        development_labels.append( audio_label )\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    development_labels = np.array(development_labels)\n",
    "    probabilities = np.array(probabilities)\n",
    "\n",
    "    scores_geniue = []\n",
    "    scores_spoof = []\n",
    "    prob_genuine = []\n",
    "    prob_spoof = []\n",
    "\n",
    "    for i in range(development_labels.shape[0]):\n",
    "        if development_labels[i][0] == 1 :\n",
    "            scores_geniue.append(scores[i])\n",
    "            prob_genuine.append(probabilities[i])\n",
    "        elif development_labels[i][1] == 1:\n",
    "            scores_spoof.append(scores[i])\n",
    "            prob_spoof.append(probabilities[i])\n",
    "\n",
    "    scores_geniue = np.array(scores_geniue)\n",
    "    scores_spoof = np.array(scores_spoof)\n",
    "    prob_genuine = np.array(prob_genuine)\n",
    "    prob_spoof = np.array(prob_spoof)\n",
    "    \n",
    "    a,b = cal_eer(scores_geniue, scores_spoof)\n",
    "    \n",
    "    score_path = os.path.join(sp_path, \"scores\")\n",
    "    prob_path = os.path.join(sp_path, \"probabilities\")\n",
    "    \n",
    "    if not os.path.exists(score_path):\n",
    "        os.makedirs(score_path)\n",
    "        \n",
    "    if not os.path.exists(prob_path):\n",
    "        os.makedirs(prob_path)\n",
    "        \n",
    "    prob_file = \"probabilities_\"+str(index)\n",
    "    sc_file = \"scores_\"+str(index)\n",
    "    savemat(os.path.join(score_path, sc_file), { 'genuine':scores_geniue, 'spoof':scores_spoof, 'eer' : a*100 })\n",
    "    savemat(os.path.join(prob_path, prob_file), { 'genuine':prob_genuine, 'spoof':prob_spoof })\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config = config)\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep = None)\n",
    "\n",
    "features_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\overlapData_90D'\n",
    "development_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\devoverlapData_90D'\n",
    "eval_features_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\evalcontextData_90D'\n",
    "model_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\Models_90D_caps_net_v2_3c_1fc_512'\n",
    "\n",
    "dev_sp_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\Dev_sp_90D_caps_net_v2_3c_1fc_512'\n",
    "eval_sp_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\Eval_sp_90D_caps_net_v2_3c_1fc_512'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize session\n",
    "\n",
    "session.run(init)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(dev_sp_path):\n",
    "    os.makedirs(dev_sp_path)\n",
    "\n",
    "batches = (len(list(os.listdir(features_path))))//2\n",
    "\n",
    "for i in range(0,10):\n",
    "    for j in range(1,batches+1):\n",
    "        batch_name = 'batch_'+str(j)+'.npy'\n",
    "        label_name = 'label_'+str(j)+'.npy'\n",
    "        \n",
    "        features = np.load(os.path.join(features_path,batch_name))\n",
    "        labels = np.load(os.path.join(features_path,label_name))\n",
    "        \n",
    "        train_step.run(session = session, feed_dict = {x : features, y: labels})\n",
    "    save_path = saver.Save(session, os.path.join(model_path,'Model_'+str(i+1)))\n",
    "    \n",
    "    print(\"iteration   \", (i+1))\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
