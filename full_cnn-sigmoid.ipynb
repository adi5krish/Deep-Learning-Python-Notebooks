{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN and Out variables for data \n",
    "dimension = 120\n",
    "fps = 100 #frames per second\n",
    "filters = 128\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, dimension, fps])  #Inputs\n",
    "y = tf.placeholder(tf.float32, [None, 2])   #Labels\n",
    "keep_prob = tf.placeholder(dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 120, 100, 1), dtype=float32)\n",
      "Tensor(\"Sigmoid:0\", shape=(?, 1, 98, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#convolution Layer - 1 \n",
    "weights_conv1 = tf.get_variable( \"weights_conv1\", shape = [dimension, 3, 1, filters], \n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "bias_conv1 = tf.get_variable( \"bias_conv1\", shape = [filters],\n",
    "                             initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "input_x = tf.reshape(x, [-1, dimension, fps, 1])\n",
    "print(input_x)\n",
    "\n",
    "#output\n",
    "conv1 = tf.nn.conv2d( input_x, weights_conv1, strides=[1, 1, 1, 1], padding='VALID') \n",
    "conv1_out = tf.nn.sigmoid( conv1 + bias_conv1 )\n",
    "conv1_drop = tf.nn.dropout(conv1_out, keep_prob)\n",
    "print(conv1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_1/mul:0\", shape=(?, 1, 96, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#convolution layer - 2\n",
    "\n",
    "weights_conv2 = tf.get_variable( \"weights_conv2\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv2 = tf.get_variable(\"bias_conv2\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "#output\n",
    "conv2 = tf.nn.conv2d( conv1_drop, weights_conv2, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "conv2_out = tf.nn.sigmoid( conv2 + bias_conv2)\n",
    "conv2_drop = tf.nn.dropout(conv2_out, keep_prob)\n",
    "print(conv2_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_2/mul:0\", shape=(?, 1, 94, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#convolution layer - 3\n",
    "\n",
    "weights_conv3 = tf.get_variable( \"weights_conv3\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv3 = tf.get_variable(\"bias_conv3\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "#output\n",
    "conv3 = tf.nn.conv2d( conv2_drop, weights_conv3, strides = [1, 1, 1, 1], padding ='VALID')\n",
    "conv3_out = tf.nn.sigmoid( conv3 + bias_conv3)\n",
    "conv3_drop = tf.nn.dropout(conv3_out, keep_prob)\n",
    "print(conv3_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_3/mul:0\", shape=(?, 1, 47, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Max pooling layer\n",
    "\n",
    "weights_conv4 = tf.get_variable( \"weights_conv4\", shape = [ 1, 2, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv4 = tf.get_variable(\"bias_conv4\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv4 = tf.nn.conv2d( conv3_drop, weights_conv4, strides = [1, 2, 2, 1], padding = \"VALID\")\n",
    "conv4_out = tf.nn.sigmoid( conv4 + bias_conv4 )\n",
    "conv4_drop = tf.nn.dropout(conv4_out, keep_prob)\n",
    "pool_out = conv4_drop\n",
    "print(pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_4/mul:0' shape=(?, 1, 45, 128) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv5 = tf.get_variable( \"weights_conv5\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv5 = tf.get_variable(\"bias_conv5\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv5 = tf.nn.conv2d( pool_out, weights_conv5, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv5_out = tf.nn.sigmoid( conv5 + bias_conv5 )\n",
    "conv5_drop = tf.nn.dropout(conv5_out, keep_prob)\n",
    "conv5_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_5/mul:0' shape=(?, 1, 43, 128) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv6 = tf.get_variable( \"weights_conv6\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv6 = tf.get_variable(\"bias_conv6\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv6 = tf.nn.conv2d( conv5_drop, weights_conv6, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv6_out = tf.nn.sigmoid( conv6 + bias_conv6 )\n",
    "conv6_drop = tf.nn.dropout(conv6_out, keep_prob)\n",
    "conv6_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_6/mul:0' shape=(?, 1, 41, 128) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv7 = tf.get_variable( \"weights_conv7\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv7 = tf.get_variable(\"bias_conv7\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv7 = tf.nn.conv2d( conv6_drop, weights_conv7, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv7_out = tf.nn.sigmoid( conv7 + bias_conv7 )\n",
    "conv7_drop = tf.nn.dropout( conv7_out, keep_prob)\n",
    "conv7_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_7/mul:0' shape=(?, 1, 41, 2) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv8 = tf.get_variable( \"weights_conv8\", shape = [ 1, 1, filters, 2],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv8 = tf.get_variable(\"bias_conv8\", shape = [2],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv8 = tf.nn.conv2d( conv7_drop, weights_conv8, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv8_out = tf.nn.sigmoid( conv8 + bias_conv8 )\n",
    "conv8_drop = tf.nn.dropout( conv8_out, keep_prob)\n",
    "conv8_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid_8:0' shape=(?, 1, 1, 2) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final output layer\n",
    "weights_final = tf.get_variable( \"weights_final\", shape = [ 1, 41, 2, 2],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_final = tf.get_variable(\"bias_final\", shape = [2],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv_final = tf.nn.conv2d( conv8_drop, weights_final, strides = [1, 41, 1, 1], padding = \"VALID\")\n",
    "conv_final = tf.nn.sigmoid( conv_final + bias_final )\n",
    "conv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = tf.reshape(conv_final, shape = [-1, 2])\n",
    "\n",
    "output = tf.nn.softmax(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses and optimizers\n",
    "\n",
    "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = final_output))\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "correct_predictions = tf.equal( tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean( tf.cast( correct_predictions, tf.float32 ))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# matric for testing on development \n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "test_path =\"E:\\\\Hemlata_CSL\\\\MFCC\\\\CNN_input_dev_data\"\n",
    "\n",
    "for folders in os.listdir(test_path):\n",
    "    print(folders)\n",
    "    features = np.load(os.path.join(test_path, folders, \"feature_image.npy\"))\n",
    "    print(features.shape)\n",
    "    labels = np.load(os.path.join(test_path, folders, \"label_image.npy\"))\n",
    "    for i in range(labels.shape[0]):\n",
    "        test_features.append(features[i])\n",
    "        test_labels.append(labels[i])\n",
    "    \n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing tensors using sessoion\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "features_path = \"/home/speechlab/ASV/siva/IFCC/overlap_data_100_50\"\n",
    "development_path = \"/home/speechlab/ASV/siva/IFCC/dev_overlap_data_100_50\"\n",
    "#evaluation_path = \"E:\\\\Hemlata_CSL\\\\MFCC\\\\CNN_input_testing_eval\"\n",
    "model_path = \"/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/\"\n",
    "    \n",
    "dev_sp_path =\"/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/dev\"\n",
    "#eva_sp_path = \"E:\\\\Hemlata_CSL\\\\MFCC\\\\4_conv\\\\eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eer(scores_true, scores_false):\n",
    "    \n",
    "    \"\"\" Calculate EER\n",
    "        Args:\n",
    "            scores_true: A score list of positive samples\n",
    "            scores_false: A score list of negative samples\n",
    "        Return:\n",
    "            (EER, threshold)\n",
    "        Note:\n",
    "            Here, the threshold is set, and if the score is higher than or equal to the threshold,\n",
    "            the decision is passed, and the decision is rejected as below.\n",
    "    \"\"\"\n",
    "    min1 = min(scores_true)\n",
    "    min2 = min(scores_false)\n",
    "    low = min(min1, min2)\n",
    "    max1 = max(scores_true)\n",
    "    max2 = max(scores_false)\n",
    "    high = max(max1, max2)\n",
    "    FAR = -55\n",
    "    FRR = -55\n",
    "    mid = -100\n",
    "    # Bisection find threshold\n",
    "    while True:\n",
    "        bef_FAR = FAR \n",
    "        bef_FRR = FRR\n",
    "        bef_mid = mid\n",
    "        mid = (high + low) / 2\n",
    "        FRR = sum([1 for s in scores_true if s < mid]) / len(scores_true)\n",
    "        FAR = sum([1 for s in scores_false if s >= mid]) / len(scores_false)\n",
    "        #print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "\n",
    "        if abs(FRR - FAR) < 1e-7:\n",
    "            print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "            break\n",
    "\n",
    "        if FRR < FAR:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "            \n",
    "        if bef_FAR == FAR :\n",
    "            if bef_FRR == FRR :\n",
    "                if bef_mid == mid :\n",
    "                    print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "                    break\n",
    "\n",
    "    EER  =  FRR\n",
    "    return EER, (high + low) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "def get_EER(test_path, index, sp_path ):\n",
    "    scores = []\n",
    "    development_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    #test_path = \"C:\\\\Users\\\\project1\\\\Desktop\\\\Siva\\\\HT_IFCC_hemlata\\\\CNN_input_testing_dev\"\n",
    "    indexs = len(list(os.listdir(test_path)))//2\n",
    "    \n",
    "    for folders in range(indexs):\n",
    "        features = np.load(os.path.join(test_path, \"features\"+str(folders)+\".npy\"))\n",
    "        labels = np.load(os.path.join(test_path, \"labels\"+str(folders)+\".npy\"))\n",
    "        patches = labels.shape[0]\n",
    "        patch_prob = session.run(output, feed_dict = {x:features, keep_prob:1.0})\n",
    "        final_prob = np.zeros([2])\n",
    "        \n",
    "        for i in range(patches):\n",
    "            if(patch_prob[i][0] == 0):\n",
    "                patch_prob[i][0] = 1e-25\n",
    "            if(patch_prob[i][1] == 0):\n",
    "                patch_prob[i][1] = 1e-25\n",
    "                \n",
    "            final_prob[0] = final_prob[0] + np.log(patch_prob[i][0])\n",
    "            final_prob[1] = final_prob[1] + np.log(patch_prob[i][1])\n",
    "\n",
    "        final_prob = final_prob / patches\n",
    "        score = (final_prob[0]) - (final_prob[1])\n",
    "        audio_label = labels[0]\n",
    "\n",
    "        scores.append(score)\n",
    "        probabilities.append( np.mean(patch_prob, axis=0) )\n",
    "        development_labels.append( audio_label )\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    development_labels = np.array(development_labels)\n",
    "    probabilities = np.array(probabilities)\n",
    "\n",
    "    scores_geniue = []\n",
    "    scores_spoof = []\n",
    "    prob_genuine = []\n",
    "    prob_spoof = []\n",
    "\n",
    "    for i in range(development_labels.shape[0]):\n",
    "        if development_labels[i][0] == 1 :\n",
    "            scores_geniue.append(scores[i])\n",
    "            prob_genuine.append(probabilities[i])\n",
    "        elif development_labels[i][1] == 1:\n",
    "            scores_spoof.append(scores[i])\n",
    "            prob_spoof.append(probabilities[i])\n",
    "\n",
    "    scores_geniue = np.array(scores_geniue)\n",
    "    scores_spoof = np.array(scores_spoof)\n",
    "    prob_genuine = np.array(prob_genuine)\n",
    "    prob_spoof = np.array(prob_spoof)\n",
    "    \n",
    "    a,b = cal_eer(scores_geniue, scores_spoof)\n",
    "    \n",
    "    score_path = os.path.join(sp_path, \"scores\")\n",
    "    prob_path = os.path.join(sp_path, \"probabilities\")\n",
    "    \n",
    "    if not os.path.exists(score_path):\n",
    "        os.makedirs(score_path)\n",
    "    if not os.path.exists(prob_path):\n",
    "        os.makedirs(prob_path)\n",
    "        \n",
    "    prob_file = \"probabilities_\"+str(index)\n",
    "    sc_file = \"scores_\"+str(index)\n",
    "    savemat(os.path.join(score_path, sc_file), { 'genuine':scores_geniue, 'spoof':scores_spoof, 'eer' : a*100 })\n",
    "    savemat(os.path.join(prob_path, prob_file), { 'genuine':prob_genuine, 'spoof':prob_spoof })\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "time.sleep(20)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration    1 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    2 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    3 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/2 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    4 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/3 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    5 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/4 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    6 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/5 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    7 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/6 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    8 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/7 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    9 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/8 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    10 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/9 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    11 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    12 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/11 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    13 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/12 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    14 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/13 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    15 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/14 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    16 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/15 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    17 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/16 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    18 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/17 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    19 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/18 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    20 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/19 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    21 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    22 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/21 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    23 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/22 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    24 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/23 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    25 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/24 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    26 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/25 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    27 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/26 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    28 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/27 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    29 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/28 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    30 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/29 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    31 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/30 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    32 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/31 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    33 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/32 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    34 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/33 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    35 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/34 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    36 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/35 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    37 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/36 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    38 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/37 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    39 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/38 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    40 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/39 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    41 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/40 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    42 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/41 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    43 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/42 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    44 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/43 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    45 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/44 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    46 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/45 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    47 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/46 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    48 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/47 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    49 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/48 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "iteration    50 \n",
      "\n",
      "INFO:tensorflow:/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/49 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "#Training and testing accuracy\n",
    "session.run(init)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    \n",
    "# if not os.path.exists(dev_sp_path):\n",
    "#     os.makedirs(dev_sp_path)\n",
    "    \n",
    "batches = (len(list(os.listdir(features_path))))//2\n",
    "    \n",
    "for i in range(0,50):\n",
    "    for j in range(1,batches+1):  #number of batches\n",
    "        filename = \"batch_\"+str(j)+\".npy\"\n",
    "        labelsname= \"label_\"+str(j)+\".npy\"\n",
    "        \n",
    "        features = np.load(os.path.join(features_path, filename))\n",
    "        labels = np.load(os.path.join(features_path, labelsname))\n",
    "\n",
    "        train_step.run(session = session,feed_dict={ x:features[:1024], y:labels[:1024], keep_prob:1.0})\n",
    "        train_step.run(session = session,feed_dict={ x:features[1024:], y:labels[1024:], keep_prob:1.0})\n",
    "        \n",
    "    print(\"iteration   \",(i+1),\"\\n\")\n",
    "    #test_accuracy = accuracy.eval(session = session, feed_dict = { x:test_features, y:test_labels, keep_prob:1.0 })\n",
    "    #print(\"iteration   \",(i+1),\"   dev_accuracy    \",test_accuracy)    \n",
    "    #print()\n",
    "    save_path = saver.save(session, model_path +str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/1\n",
      "iteration   2\n",
      "FRR   0.6911111111111111  FAR    0.696954732510288    mid    -0.9293453594048817\n",
      " develop eer   0.6911111111111111\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/2\n",
      "iteration   3\n",
      "FRR   0.6698148148148149  FAR    0.6983539094650206    mid    -0.9633228128606623\n",
      " develop eer   0.6698148148148149\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/3\n",
      "iteration   4\n",
      "FRR   0.0  FAR    1.0    mid    -0.9775620400905609\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/4\n",
      "iteration   5\n",
      "FRR   0.0  FAR    1.0    mid    -0.9850176572799683\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/5\n",
      "iteration   6\n",
      "FRR   0.0  FAR    1.0    mid    -0.989441990852356\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/6\n",
      "iteration   7\n",
      "FRR   0.0  FAR    1.0    mid    -0.9922868311405182\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/7\n",
      "iteration   8\n",
      "FRR   0.0  FAR    1.0    mid    -0.9942202568054199\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/8\n",
      "iteration   9\n",
      "FRR   0.0  FAR    1.0    mid    -0.9955883026123047\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/9\n",
      "iteration   10\n",
      "FRR   0.0  FAR    1.0    mid    -0.996585488319397\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/10\n",
      "iteration   11\n",
      "FRR   0.0  FAR    1.0    mid    -0.9973294138908386\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/11\n",
      "iteration   12\n",
      "FRR   0.0  FAR    1.0    mid    -0.9978941679000854\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/12\n",
      "iteration   13\n",
      "FRR   0.0  FAR    1.0    mid    -0.9983288049697876\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/13\n",
      "iteration   14\n",
      "FRR   0.0  FAR    1.0    mid    -0.9986671507358551\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/14\n",
      "iteration   15\n",
      "FRR   0.0  FAR    1.0    mid    -0.9989327788352966\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/15\n",
      "iteration   16\n",
      "FRR   0.0  FAR    1.0    mid    -0.9991427063941956\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/16\n",
      "iteration   17\n",
      "FRR   0.0  FAR    1.0    mid    -0.9993098080158234\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/17\n",
      "iteration   18\n",
      "FRR   0.0  FAR    1.0    mid    -0.9994431138038635\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/18\n",
      "iteration   19\n",
      "FRR   0.0  FAR    1.0    mid    -0.9995498657226562\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/19\n",
      "iteration   20\n",
      "FRR   0.0  FAR    1.0    mid    -0.9996357560157776\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/20\n",
      "iteration   21\n",
      "FRR   0.0  FAR    1.0    mid    -0.999704897403717\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/21\n",
      "iteration   22\n",
      "FRR   0.0  FAR    1.0    mid    -0.9997606873512268\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/22\n",
      "iteration   23\n",
      "FRR   0.0  FAR    1.0    mid    -0.9998057186603546\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/23\n",
      "iteration   24\n",
      "FRR   0.0  FAR    1.0    mid    -0.9998424053192139\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/24\n",
      "iteration   25\n",
      "FRR   0.0  FAR    1.0    mid    -0.999872088432312\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/25\n",
      "iteration   26\n",
      "FRR   0.0  FAR    1.0    mid    -0.9998960494995117\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/26\n",
      "iteration   27\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999154806137085\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/27\n",
      "iteration   28\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999313354492188\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/28\n",
      "iteration   29\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999441802501678\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/29\n",
      "iteration   30\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999545812606812\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/30\n",
      "iteration   31\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999630749225616\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/31\n",
      "iteration   32\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999699592590332\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/32\n",
      "iteration   33\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999756217002869\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/33\n",
      "iteration   34\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999800324440002\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/34\n",
      "iteration   35\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999839663505554\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/35\n",
      "iteration   36\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999867081642151\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/36\n",
      "iteration   37\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999893605709076\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/37\n",
      "iteration   38\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999912083148956\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/38\n",
      "iteration   39\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999929666519165\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/39\n",
      "iteration   40\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999941289424896\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/40\n",
      "iteration   41\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999952018260956\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/41\n",
      "iteration   42\n",
      "FRR   0.0  FAR    1.0    mid    -0.999996155500412\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/42\n",
      "iteration   43\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999969303607941\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   44\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999974071979523\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/44\n",
      "iteration   45\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999979734420776\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/45\n",
      "iteration   46\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999983906745911\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/46\n",
      "iteration   47\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999985992908478\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/47\n",
      "iteration   48\n",
      "FRR   0.0  FAR    1.0    mid    -0.999998927116394\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/48\n",
      "iteration   49\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999991357326508\n",
      " develop eer   0.0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/49\n",
      "iteration   50\n",
      "FRR   0.0  FAR    1.0    mid    -0.9999991357326508\n",
      " develop eer   0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "with tf.Session(config=config) as session:\n",
    "    for i in range(1,50):\n",
    "        saver.restore(session, model_path +str(i))\n",
    "        print(\"iteration  \",(i+1))\n",
    "        eer_dev = get_EER(development_path, (i+1), dev_sp_path)\n",
    "        print(\" develop eer  \",eer_dev)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "with tf.Session(config=config) as session:\n",
    "    for i in range(0,100):\n",
    "        saver.restore(session, model_path +str(i))\n",
    "        print(\"iteration  \",(i+1))\n",
    "        eer_eval = get_EER(evaluation_path, (i+1), eva_sp_path)\n",
    "        print(\" evaluat eer  \",eer_eval)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "def get_ind_score(test_path, index, sp_path, tag ):\n",
    "    two_scores = []\n",
    "    \n",
    "    for folders in os.listdir(test_path):\n",
    "        features = np.load(os.path.join(test_path, folders, \"feature_image.npy\"))\n",
    "        labels = np.load(os.path.join(test_path, folders, \"label_image.npy\"))\n",
    "        patches = labels.shape[0]\n",
    "        patch_prob = session.run(output1, feed_dict = {x:features, keep_prob : 1.0})\n",
    "        final_prob = np.zeros([2])\n",
    "        \n",
    "        for i in range(patches):\n",
    "            if(patch_prob[i][0] == 0):\n",
    "                patch_prob[i][0] = 1e-25\n",
    "            if(patch_prob[i][1] == 0):\n",
    "                patch_prob[i][1] = 1e-25\n",
    "                \n",
    "            final_prob[0] = final_prob[0] + np.log(patch_prob[i][0])\n",
    "            final_prob[1] = final_prob[1] + np.log(patch_prob[i][1])\n",
    "\n",
    "        final_prob = final_prob / patches\n",
    "        two_scores.append(final_prob)\n",
    "\n",
    "    two_scores = np.array(two_scores)\n",
    "    score_path = os.path.join(sp_path, tag+\"_ind_scores\")\n",
    "    \n",
    "    if not os.path.exists(score_path):\n",
    "        os.makedirs(score_path)\n",
    "        \n",
    "    sc_file = \"llk_genuine_llk_spoof_\"+tag+\"_\"+str(index)\n",
    "    savemat(os.path.join(score_path, sc_file), {'ind_scores':two_scores} )\n",
    "    print(\"Done\")\n",
    "    \n",
    "    \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "dev_ite  = 90\n",
    "eval_ite = \n",
    "with tf.Session() as session:\n",
    "    saver.restore(session, model_path +str(dev_ite-1))\n",
    "    print(\"iteration  \",(dev_ite))\n",
    "    get_ind_score(development_path, (dev_ite), dev_sp_path,\"dev\")\n",
    "    \n",
    "    saver.restore(session, model_path +str(eval_ite-1))\n",
    "    print(\"iteration  \",(eval_ite))\n",
    "    get_ind_score(evaluation_path, (eval_ite), eva_sp_path,\"eval\")\n",
    "    \n",
    "    print()    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as session:\n",
    "    for i in range(55, 75):\n",
    "        saver.restore(session, model_path +str(i))\n",
    "        print(\"iteration  \",(i+1))\n",
    "        eer_eval = get_EER(evaluation_path, (i+1), eva_sp_path)\n",
    "        print(\" evaluat eer  \",eer_eval)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
